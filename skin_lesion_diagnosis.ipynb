{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9515 validated image filenames.\n",
      "Found 500 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "df=pd.read_csv(r'data/ISIC2018_Task3_Training_GroundTruth/ISIC2018_Task3_Training_GroundTruth.csv')\n",
    "df['image'] = df['image']+'.jpg'\n",
    "datagen=ImageDataGenerator(rescale=1./255,validation_split=0.05,\n",
    "                           featurewise_center=True,featurewise_std_normalization=True,\n",
    "                           shear_range=0.2,zoom_range=0.2,\n",
    "                           rotation_range=10,width_shift_range=0.1,\n",
    "                           height_shift_range=0.1)\n",
    "IMG_HEIGHT,IMG_WIDTH = 224,224\n",
    "train_generator=datagen.flow_from_dataframe(dataframe=df, directory=\"data/ISIC2018_Task3_Training_Input\", \n",
    "                                            x_col=\"image\", y_col=['MEL','NV','BCC','AKIEC','BKL','DF','VASC'], \n",
    "                                            class_mode=\"raw\", \n",
    "                                            target_size=(IMG_HEIGHT,IMG_WIDTH), batch_size=100,\n",
    "                                           subset='training')\n",
    "valid_generator=datagen.flow_from_dataframe(dataframe=df, directory=\"data/ISIC2018_Task3_Training_Input\", \n",
    "                                            x_col=\"image\", y_col=['MEL','NV','BCC','AKIEC','BKL','DF','VASC'], \n",
    "                                            class_mode=\"raw\", \n",
    "                                            target_size=(IMG_HEIGHT,IMG_WIDTH), batch_size=100,\n",
    "                                           subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEL  NV   BCC  AKIEC  BKL  DF   VASC\n",
      "0.0  0.0  0.0  0.0    0.0  0.0  1.0      142\n",
      "                           1.0  0.0      115\n",
      "                      1.0  0.0  0.0     1099\n",
      "               1.0    0.0  0.0  0.0      327\n",
      "          1.0  0.0    0.0  0.0  0.0      514\n",
      "     1.0  0.0  0.0    0.0  0.0  0.0     6705\n",
      "1.0  0.0  0.0  0.0    0.0  0.0  0.0     1113\n",
      "dtype: int64\n",
      "[142, 115, 1099, 327, 514, 6705, 1113]\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: [(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0), (0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0), (0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0), (0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0), (0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0), (0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0), (1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)]\n",
      "{0: 0.11113330004992511, 1: 0.6694957563654518, 2: 0.05132301547678482, 3: 0.032651023464802795, 4: 0.10973539690464304, 5: 0.011482775836245632, 6: 0.014178731902146779}\n"
     ]
    }
   ],
   "source": [
    "classes = ['MEL','NV','BCC','AKIEC','BKL','DF','VASC']\n",
    "\n",
    "df1=df.drop(['image'],axis=1)\n",
    "print(df1.groupby(classes).size())\n",
    "grous = list(df1.groupby(classes).size())\n",
    "g1=df1.groupby(classes).count()\n",
    "print(grous)\n",
    "print(g1)\n",
    "total_weights = sum(grous)\n",
    "weights1 = [x/total_weights for x in reversed(grous)]\n",
    "weights = {x : weights1[x] for x in range(len(weights1))} \n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import Sequential\n",
    "# from keras.layers import Conv2D,Activation,MaxPooling2D,Dropout,Flatten,Dense\n",
    "# from keras import optimizers\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_HEIGHT,IMG_WIDTH, 3)))\n",
    "# model.add(MaxPooling2D((2, 2)))\n",
    "# model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "# model.add(MaxPooling2D((2, 2)))\n",
    "# model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "# model.add(MaxPooling2D((2, 2)))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(128, activation='relu'))\n",
    "# model.add(Dropout(0.1))\n",
    "# model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "# model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# # model = Sequential()\n",
    "# # model.add(Conv2D(32, (3, 3), padding='same',\n",
    "# #                  input_shape=(32,32,3)))\n",
    "# # model.add(Activation('relu'))\n",
    "# # model.add(Conv2D(32, (3, 3)))\n",
    "# # model.add(Activation('relu'))\n",
    "# # model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# # model.add(Dropout(0.25))\n",
    "\n",
    "# # model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "# # model.add(Activation('relu'))\n",
    "# # model.add(Conv2D(64, (3, 3)))\n",
    "# # model.add(Activation('relu'))\n",
    "# # model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# # model.add(Dropout(0.25))\n",
    "\n",
    "# # model.add(Flatten())\n",
    "# # model.add(Dense(512))\n",
    "# # model.add(Activation('relu'))\n",
    "# # model.add(Dropout(0.5))\n",
    "# # model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# # model.compile(optimizers.rmsprop(lr=0.0001),\n",
    "# # loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "# STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "# STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
    "# model.fit_generator(generator=train_generator,\n",
    "#                     steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "#                     validation_data=valid_generator,\n",
    "#                     validation_steps=STEP_SIZE_VALID,\n",
    "#                     epochs=5,\n",
    "#                    class_weight=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user1/anaconda3/lib/python3.7/site-packages/keras_preprocessing/image/image_data_generator.py:716: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n",
      "/home/user1/anaconda3/lib/python3.7/site-packages/keras_preprocessing/image/image_data_generator.py:724: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2/95 [..............................] - ETA: 2:45 - loss: 0.6796 - accuracy: 0.3400"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-19ff333bb850>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m                     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSTEP_SIZE_VALID\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                    class_weight=weights)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    608\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m                     \u001b[0mfuture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m                     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m                     \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224,224,3)) \n",
    "# Freeze convolutional layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False \n",
    "\n",
    "#     model.add(Flatten())\n",
    "#     model.add(Dense(4096, activation='relu'))\n",
    "#     model.add(Dropout(0.5))\n",
    "#     model.add(Dense(4096, activation='relu'))\n",
    "#     model.add(Dropout(0.5))\n",
    "#     model.add(Dense(1000, activation='softmax'))\n",
    "# note we exclude the above final dense layers, and add the dense layers below, so we could retrain it ourselves\n",
    "\n",
    "x = base_model.output\n",
    "x = Flatten()(x) # flatten from convolution tensor output \n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(7, activation='softmax')(x) # should match # of classes predicted\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9),\n",
    "            loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
    "model.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    epochs=100,\n",
    "                   class_weight=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_13 (Conv2D)           (None, 224, 224, 32)      896       \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 224, 224, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 112, 112, 64)      18496     \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 112, 112, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 200704)            0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               25690240  \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 25,756,711\n",
      "Trainable params: 25,756,711\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user1/anaconda3/lib/python3.7/site-packages/keras_preprocessing/image/image_data_generator.py:716: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n",
      "/home/user1/anaconda3/lib/python3.7/site-packages/keras_preprocessing/image/image_data_generator.py:724: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 [==============================] - 155s 2s/step - loss: 1.8026 - accuracy: 0.6493 - val_loss: 1.1508 - val_accuracy: 0.6640\n",
      "Epoch 2/100\n",
      "95/95 [==============================] - 153s 2s/step - loss: 1.0436 - accuracy: 0.6694 - val_loss: 1.0549 - val_accuracy: 0.6640\n",
      "Epoch 3/100\n",
      "95/95 [==============================] - 154s 2s/step - loss: 0.9854 - accuracy: 0.6694 - val_loss: 0.9315 - val_accuracy: 0.6660\n",
      "Epoch 4/100\n",
      "95/95 [==============================] - 154s 2s/step - loss: 0.9503 - accuracy: 0.6638 - val_loss: 0.8486 - val_accuracy: 0.6640\n",
      "Epoch 5/100\n",
      "95/95 [==============================] - 153s 2s/step - loss: 0.9226 - accuracy: 0.6691 - val_loss: 0.8182 - val_accuracy: 0.6760\n",
      "Epoch 6/100\n",
      "95/95 [==============================] - 154s 2s/step - loss: 0.9097 - accuracy: 0.6700 - val_loss: 0.8376 - val_accuracy: 0.6720\n",
      "Epoch 7/100\n",
      "95/95 [==============================] - 154s 2s/step - loss: 0.8898 - accuracy: 0.6731 - val_loss: 0.7164 - val_accuracy: 0.6740\n",
      "Epoch 8/100\n",
      "95/95 [==============================] - 153s 2s/step - loss: 0.8813 - accuracy: 0.6767 - val_loss: 0.6949 - val_accuracy: 0.6720\n",
      "Epoch 9/100\n",
      "95/95 [==============================] - 155s 2s/step - loss: 0.8492 - accuracy: 0.6763 - val_loss: 0.7500 - val_accuracy: 0.6880\n",
      "Epoch 10/100\n",
      "95/95 [==============================] - 152s 2s/step - loss: 0.8424 - accuracy: 0.6851 - val_loss: 0.7672 - val_accuracy: 0.6840\n",
      "Epoch 11/100\n",
      "95/95 [==============================] - 155s 2s/step - loss: 0.8242 - accuracy: 0.6863 - val_loss: 0.7298 - val_accuracy: 0.7140\n",
      "Epoch 12/100\n",
      "95/95 [==============================] - 152s 2s/step - loss: 0.8304 - accuracy: 0.6879 - val_loss: 0.6381 - val_accuracy: 0.7060\n",
      "Epoch 13/100\n",
      "95/95 [==============================] - 154s 2s/step - loss: 0.8202 - accuracy: 0.6937 - val_loss: 0.6717 - val_accuracy: 0.7340\n",
      "Epoch 14/100\n",
      "95/95 [==============================] - 153s 2s/step - loss: 0.8019 - accuracy: 0.7001 - val_loss: 0.7844 - val_accuracy: 0.7460\n",
      "Epoch 15/100\n",
      "95/95 [==============================] - 153s 2s/step - loss: 0.7914 - accuracy: 0.7021 - val_loss: 0.7352 - val_accuracy: 0.7340\n",
      "Epoch 16/100\n",
      "95/95 [==============================] - 154s 2s/step - loss: 0.7982 - accuracy: 0.6984 - val_loss: 1.0139 - val_accuracy: 0.7220\n",
      "Epoch 17/100\n",
      "95/95 [==============================] - 153s 2s/step - loss: 0.7713 - accuracy: 0.7056 - val_loss: 0.6299 - val_accuracy: 0.7380\n",
      "Epoch 18/100\n",
      "95/95 [==============================] - 155s 2s/step - loss: 0.7904 - accuracy: 0.6938 - val_loss: 0.8013 - val_accuracy: 0.7420\n",
      "Epoch 19/100\n",
      "95/95 [==============================] - 153s 2s/step - loss: 0.7625 - accuracy: 0.7108 - val_loss: 0.7543 - val_accuracy: 0.7360\n",
      "Epoch 20/100\n",
      "95/95 [==============================] - 154s 2s/step - loss: 0.7850 - accuracy: 0.6990 - val_loss: 0.6395 - val_accuracy: 0.7260\n",
      "Epoch 21/100\n",
      "95/95 [==============================] - 153s 2s/step - loss: 0.7651 - accuracy: 0.7082 - val_loss: 0.8529 - val_accuracy: 0.7460\n",
      "Epoch 22/100\n",
      "95/95 [==============================] - 155s 2s/step - loss: 0.7588 - accuracy: 0.7070 - val_loss: 0.9038 - val_accuracy: 0.7480\n",
      "Epoch 23/100\n",
      "95/95 [==============================] - 154s 2s/step - loss: 0.7661 - accuracy: 0.7047 - val_loss: 0.7564 - val_accuracy: 0.7360\n",
      "Epoch 24/100\n",
      "95/95 [==============================] - 153s 2s/step - loss: 0.7476 - accuracy: 0.7170 - val_loss: 0.6120 - val_accuracy: 0.7440\n",
      "Epoch 25/100\n",
      "95/95 [==============================] - 156s 2s/step - loss: 0.7516 - accuracy: 0.7143 - val_loss: 0.7032 - val_accuracy: 0.7420\n",
      "Epoch 26/100\n",
      "95/95 [==============================] - 152s 2s/step - loss: 0.7638 - accuracy: 0.7084 - val_loss: 0.6912 - val_accuracy: 0.7380\n",
      "Epoch 27/100\n",
      "95/95 [==============================] - 155s 2s/step - loss: 0.7452 - accuracy: 0.7102 - val_loss: 0.7700 - val_accuracy: 0.7440\n",
      "Epoch 28/100\n",
      "95/95 [==============================] - 153s 2s/step - loss: 0.7378 - accuracy: 0.7193 - val_loss: 0.7470 - val_accuracy: 0.7400\n",
      "Epoch 29/100\n",
      "95/95 [==============================] - 154s 2s/step - loss: 0.7523 - accuracy: 0.7140 - val_loss: 0.6182 - val_accuracy: 0.7760\n",
      "Epoch 30/100\n",
      "95/95 [==============================] - 153s 2s/step - loss: 0.7424 - accuracy: 0.7213 - val_loss: 0.8194 - val_accuracy: 0.7380\n",
      "Epoch 31/100\n",
      "95/95 [==============================] - 154s 2s/step - loss: 0.7469 - accuracy: 0.7148 - val_loss: 0.8090 - val_accuracy: 0.7500\n",
      "Epoch 32/100\n",
      "95/95 [==============================] - 154s 2s/step - loss: 0.7357 - accuracy: 0.7216 - val_loss: 0.6028 - val_accuracy: 0.7640\n",
      "Epoch 33/100\n",
      "95/95 [==============================] - 153s 2s/step - loss: 0.7162 - accuracy: 0.7210 - val_loss: 0.5253 - val_accuracy: 0.7460\n",
      "Epoch 34/100\n",
      "95/95 [==============================] - 153s 2s/step - loss: 0.7321 - accuracy: 0.7252 - val_loss: 0.7200 - val_accuracy: 0.7500\n",
      "Epoch 35/100\n",
      "95/95 [==============================] - 154s 2s/step - loss: 0.7097 - accuracy: 0.7255 - val_loss: 0.8518 - val_accuracy: 0.7660\n",
      "Epoch 36/100\n",
      "95/95 [==============================] - 153s 2s/step - loss: 0.7264 - accuracy: 0.7209 - val_loss: 0.8121 - val_accuracy: 0.7340\n",
      "Epoch 37/100\n",
      "95/95 [==============================] - 155s 2s/step - loss: 0.7184 - accuracy: 0.7262 - val_loss: 0.5874 - val_accuracy: 0.7860\n",
      "Epoch 38/100\n",
      "95/95 [==============================] - 154s 2s/step - loss: 0.7134 - accuracy: 0.7241 - val_loss: 0.6328 - val_accuracy: 0.7760\n",
      "Epoch 39/100\n",
      "95/95 [==============================] - 152s 2s/step - loss: 0.7140 - accuracy: 0.7240 - val_loss: 0.5311 - val_accuracy: 0.7560\n",
      "Epoch 40/100\n",
      "95/95 [==============================] - 153s 2s/step - loss: 0.7027 - accuracy: 0.7304 - val_loss: 0.6697 - val_accuracy: 0.7640\n",
      "Epoch 41/100\n",
      "95/95 [==============================] - 156s 2s/step - loss: 0.6903 - accuracy: 0.7343 - val_loss: 0.5846 - val_accuracy: 0.7680\n",
      "Epoch 42/100\n",
      "95/95 [==============================] - 154s 2s/step - loss: 0.7282 - accuracy: 0.7260 - val_loss: 0.6959 - val_accuracy: 0.7680\n",
      "Epoch 43/100\n",
      "95/95 [==============================] - 153s 2s/step - loss: 0.6957 - accuracy: 0.7351 - val_loss: 0.8748 - val_accuracy: 0.7840\n",
      "Epoch 44/100\n",
      "95/95 [==============================] - 154s 2s/step - loss: 0.6916 - accuracy: 0.7329 - val_loss: 0.8739 - val_accuracy: 0.7460\n",
      "Epoch 45/100\n",
      "95/95 [==============================] - 153s 2s/step - loss: 0.7006 - accuracy: 0.7343 - val_loss: 0.7312 - val_accuracy: 0.7800\n",
      "Epoch 46/100\n",
      "95/95 [==============================] - 152s 2s/step - loss: 0.6919 - accuracy: 0.7361 - val_loss: 0.7939 - val_accuracy: 0.7540\n",
      "Epoch 47/100\n",
      "95/95 [==============================] - 156s 2s/step - loss: 0.6767 - accuracy: 0.7407 - val_loss: 0.5800 - val_accuracy: 0.7520\n",
      "Epoch 48/100\n",
      "95/95 [==============================] - 152s 2s/step - loss: 0.6982 - accuracy: 0.7327 - val_loss: 0.7685 - val_accuracy: 0.7500\n",
      "Epoch 49/100\n",
      "95/95 [==============================] - 153s 2s/step - loss: 0.6832 - accuracy: 0.7384 - val_loss: 0.6406 - val_accuracy: 0.7640\n",
      "Epoch 50/100\n",
      "95/95 [==============================] - 155s 2s/step - loss: 0.6668 - accuracy: 0.7406 - val_loss: 0.6510 - val_accuracy: 0.7820\n",
      "Epoch 51/100\n",
      "95/95 [==============================] - 154s 2s/step - loss: 0.6689 - accuracy: 0.7426 - val_loss: 0.5576 - val_accuracy: 0.7780\n",
      "Epoch 52/100\n",
      "95/95 [==============================] - 155s 2s/step - loss: 0.6829 - accuracy: 0.7380 - val_loss: 0.6013 - val_accuracy: 0.7740\n",
      "Epoch 53/100\n",
      "95/95 [==============================] - 153s 2s/step - loss: 0.6715 - accuracy: 0.7371 - val_loss: 0.6263 - val_accuracy: 0.7920\n",
      "Epoch 54/100\n",
      "95/95 [==============================] - 154s 2s/step - loss: 0.6682 - accuracy: 0.7399 - val_loss: 0.5074 - val_accuracy: 0.7720\n",
      "Epoch 55/100\n",
      "95/95 [==============================] - 155s 2s/step - loss: 0.6808 - accuracy: 0.7387 - val_loss: 0.6927 - val_accuracy: 0.7700\n",
      "Epoch 56/100\n",
      "95/95 [==============================] - 153s 2s/step - loss: 0.6708 - accuracy: 0.7376 - val_loss: 0.6754 - val_accuracy: 0.7640\n",
      "Epoch 57/100\n",
      "95/95 [==============================] - 154s 2s/step - loss: 0.6775 - accuracy: 0.7412 - val_loss: 0.5730 - val_accuracy: 0.7600\n",
      "Epoch 58/100\n",
      "95/95 [==============================] - 155s 2s/step - loss: 0.6749 - accuracy: 0.7417 - val_loss: 0.5014 - val_accuracy: 0.7680\n",
      "Epoch 59/100\n",
      "95/95 [==============================] - 154s 2s/step - loss: 0.6601 - accuracy: 0.7460 - val_loss: 0.5608 - val_accuracy: 0.7780\n",
      "Epoch 60/100\n",
      "95/95 [==============================] - 153s 2s/step - loss: 0.6736 - accuracy: 0.7441 - val_loss: 0.5791 - val_accuracy: 0.7700\n",
      "Epoch 61/100\n",
      "95/95 [==============================] - 155s 2s/step - loss: 0.6562 - accuracy: 0.7517 - val_loss: 0.5720 - val_accuracy: 0.7700\n",
      "Epoch 62/100\n",
      "95/95 [==============================] - 152s 2s/step - loss: 0.6474 - accuracy: 0.7552 - val_loss: 0.6883 - val_accuracy: 0.7700\n",
      "Epoch 63/100\n",
      "95/95 [==============================] - 156s 2s/step - loss: 0.6432 - accuracy: 0.7517 - val_loss: 0.5265 - val_accuracy: 0.7680\n",
      "Epoch 64/100\n",
      "95/95 [==============================] - 154s 2s/step - loss: 0.6481 - accuracy: 0.7497 - val_loss: 0.4971 - val_accuracy: 0.7860\n",
      "Epoch 65/100\n",
      "95/95 [==============================] - 154s 2s/step - loss: 0.6545 - accuracy: 0.7542 - val_loss: 0.5444 - val_accuracy: 0.7680\n",
      "Epoch 66/100\n",
      "95/95 [==============================] - 153s 2s/step - loss: 0.6543 - accuracy: 0.7466 - val_loss: 0.6265 - val_accuracy: 0.7720\n",
      "Epoch 67/100\n",
      "95/95 [==============================] - 155s 2s/step - loss: 0.6471 - accuracy: 0.7546 - val_loss: 0.7180 - val_accuracy: 0.7660\n",
      "Epoch 68/100\n",
      "95/95 [==============================] - 154s 2s/step - loss: 0.6447 - accuracy: 0.7522 - val_loss: 0.4833 - val_accuracy: 0.7440\n",
      "Epoch 69/100\n",
      "95/95 [==============================] - 154s 2s/step - loss: 0.6343 - accuracy: 0.7514 - val_loss: 0.7081 - val_accuracy: 0.7720\n",
      "Epoch 70/100\n",
      "95/95 [==============================] - 152s 2s/step - loss: 0.6469 - accuracy: 0.7526 - val_loss: 0.5191 - val_accuracy: 0.7720\n",
      "Epoch 71/100\n",
      "95/95 [==============================] - 155s 2s/step - loss: 0.6365 - accuracy: 0.7534 - val_loss: 0.9677 - val_accuracy: 0.7840\n",
      "Epoch 72/100\n",
      "95/95 [==============================] - 154s 2s/step - loss: 0.6551 - accuracy: 0.7515 - val_loss: 0.8454 - val_accuracy: 0.7620\n",
      "Epoch 73/100\n",
      "95/95 [==============================] - 154s 2s/step - loss: 0.6165 - accuracy: 0.7642 - val_loss: 0.7282 - val_accuracy: 0.7720\n",
      "Epoch 74/100\n",
      "95/95 [==============================] - 154s 2s/step - loss: 0.6477 - accuracy: 0.7524 - val_loss: 0.7508 - val_accuracy: 0.7600\n",
      "Epoch 75/100\n",
      "95/95 [==============================] - 155s 2s/step - loss: 0.6294 - accuracy: 0.7603 - val_loss: 0.6288 - val_accuracy: 0.7720\n",
      "Epoch 76/100\n",
      "95/95 [==============================] - 153s 2s/step - loss: 0.6593 - accuracy: 0.7502 - val_loss: 0.6208 - val_accuracy: 0.7740\n",
      "Epoch 77/100\n",
      "95/95 [==============================] - 152s 2s/step - loss: 0.6412 - accuracy: 0.7581 - val_loss: 0.6187 - val_accuracy: 0.7680\n",
      "Epoch 78/100\n",
      "95/95 [==============================] - 154s 2s/step - loss: 0.6179 - accuracy: 0.7627 - val_loss: 0.5728 - val_accuracy: 0.7640\n",
      "Epoch 79/100\n",
      "95/95 [==============================] - 155s 2s/step - loss: 0.6261 - accuracy: 0.7588 - val_loss: 0.8366 - val_accuracy: 0.7740\n",
      "Epoch 80/100\n",
      "95/95 [==============================] - 154s 2s/step - loss: 0.6206 - accuracy: 0.7634 - val_loss: 0.6352 - val_accuracy: 0.7860\n",
      "Epoch 81/100\n",
      "95/95 [==============================] - 154s 2s/step - loss: 0.6227 - accuracy: 0.7584 - val_loss: 0.6574 - val_accuracy: 0.7360\n",
      "Epoch 82/100\n",
      "95/95 [==============================] - 154s 2s/step - loss: 0.6187 - accuracy: 0.7624 - val_loss: 0.6797 - val_accuracy: 0.7700\n",
      "Epoch 83/100\n",
      "95/95 [==============================] - 154s 2s/step - loss: 0.6378 - accuracy: 0.7561 - val_loss: 0.5613 - val_accuracy: 0.7680\n",
      "Epoch 84/100\n",
      "95/95 [==============================] - 154s 2s/step - loss: 0.6232 - accuracy: 0.7597 - val_loss: 0.6423 - val_accuracy: 0.7760\n",
      "Epoch 85/100\n",
      "95/95 [==============================] - 154s 2s/step - loss: 0.6180 - accuracy: 0.7603 - val_loss: 0.6525 - val_accuracy: 0.7700\n",
      "Epoch 86/100\n",
      "95/95 [==============================] - 154s 2s/step - loss: 0.6084 - accuracy: 0.7638 - val_loss: 0.6205 - val_accuracy: 0.7640\n",
      "Epoch 87/100\n",
      "95/95 [==============================] - 154s 2s/step - loss: 0.6088 - accuracy: 0.7637 - val_loss: 0.6499 - val_accuracy: 0.7760\n",
      "Epoch 88/100\n",
      "95/95 [==============================] - 155s 2s/step - loss: 0.5953 - accuracy: 0.7689 - val_loss: 0.6248 - val_accuracy: 0.7880\n",
      "Epoch 89/100\n",
      "95/95 [==============================] - 154s 2s/step - loss: 0.5940 - accuracy: 0.7746 - val_loss: 0.9209 - val_accuracy: 0.7800\n",
      "Epoch 90/100\n",
      "95/95 [==============================] - 154s 2s/step - loss: 0.6151 - accuracy: 0.7677 - val_loss: 0.7002 - val_accuracy: 0.7900\n",
      "Epoch 91/100\n",
      "95/95 [==============================] - 154s 2s/step - loss: 0.5857 - accuracy: 0.7671 - val_loss: 0.6348 - val_accuracy: 0.7680\n",
      "Epoch 92/100\n",
      "95/95 [==============================] - 154s 2s/step - loss: 0.6020 - accuracy: 0.7668 - val_loss: 0.6509 - val_accuracy: 0.7740\n",
      "Epoch 93/100\n",
      "95/95 [==============================] - 154s 2s/step - loss: 0.5945 - accuracy: 0.7677 - val_loss: 0.7571 - val_accuracy: 0.7820\n",
      "Epoch 94/100\n",
      "95/95 [==============================] - 154s 2s/step - loss: 0.5903 - accuracy: 0.7711 - val_loss: 0.4658 - val_accuracy: 0.7780\n",
      "Epoch 95/100\n",
      "95/95 [==============================] - 153s 2s/step - loss: 0.5824 - accuracy: 0.7705 - val_loss: 0.7712 - val_accuracy: 0.7500\n",
      "Epoch 96/100\n",
      "95/95 [==============================] - 153s 2s/step - loss: 0.5924 - accuracy: 0.7711 - val_loss: 0.5948 - val_accuracy: 0.7800\n",
      "Epoch 97/100\n",
      "95/95 [==============================] - 154s 2s/step - loss: 0.5867 - accuracy: 0.7753 - val_loss: 0.6522 - val_accuracy: 0.7700\n",
      "Epoch 98/100\n",
      "95/95 [==============================] - 154s 2s/step - loss: 0.5735 - accuracy: 0.7809 - val_loss: 0.6343 - val_accuracy: 0.7720\n",
      "Epoch 99/100\n",
      "95/95 [==============================] - 153s 2s/step - loss: 0.5916 - accuracy: 0.7751 - val_loss: 0.6063 - val_accuracy: 0.7620\n",
      "Epoch 100/100\n",
      "95/95 [==============================] - 154s 2s/step - loss: 0.6044 - accuracy: 0.7722 - val_loss: 0.5295 - val_accuracy: 0.7860\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f808865bfd0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the CNN model \n",
    "# my CNN architechture is In -> [[Conv2D->relu]*2 -> MaxPool2D -> Dropout]*2 -> Flatten -> Dense -> Dropout -> Out\n",
    "input_shape = (224, 224, 3)\n",
    "num_classes = 7\n",
    "from keras.layers import MaxPool2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',padding = 'Same',input_shape=input_shape))\n",
    "model.add(Conv2D(32,kernel_size=(3, 3), activation='relu',padding = 'Same',))\n",
    "model.add(MaxPool2D(pool_size = (2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu',padding = 'Same'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu',padding = 'Same'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.40))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer = 'adam' , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Set a learning rate annealer\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=3, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)\n",
    "\n",
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
    "model.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('sam_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.57      0.67         7\n",
      "           1       0.88      0.97      0.92        62\n",
      "           2       0.60      0.75      0.67         8\n",
      "           3       1.00      0.50      0.67         6\n",
      "           4       0.69      0.60      0.64        15\n",
      "           5       0.00      0.00      0.00         1\n",
      "           6       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.83       100\n",
      "   macro avg       0.71      0.63      0.65       100\n",
      "weighted avg       0.82      0.83      0.82       100\n",
      "\n",
      "[[ 4  1  0  0  2  0  0]\n",
      " [ 0 60  1  0  1  0  0]\n",
      " [ 0  1  6  0  1  0  0]\n",
      " [ 0  1  2  3  0  0  0]\n",
      " [ 1  5  0  0  9  0  0]\n",
      " [ 0  0  1  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  1]]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "predict_this=[]\n",
    "actual=[]\n",
    "x,y = next(valid_generator)\n",
    "for i in range(len(x)):\n",
    "    #plt.imshow(x[i])\n",
    "    #plt.show()\n",
    "#     print('label:',y[i])\n",
    "    actual.append(y[i])\n",
    "    predict_this.append(x[i])\n",
    "    #print('----------------------------------------------------------------------------------------')\n",
    "np.set_printoptions(suppress=True)    \n",
    "pred = model.predict(np.array(predict_this))\n",
    "\n",
    "#pred = tf.cast(pred, tf.float32)\n",
    "# print(pred)\n",
    "# print(type(pred))\n",
    "pred = np.argmax(pred, axis=1)\n",
    "actual = np.argmax(actual, axis=1)\n",
    "# print(pred)\n",
    "# print(actual)\n",
    "# if actual.all()==pred.all():\n",
    "#     print('WIN!!!!!!!!!!!!!!!')\n",
    "cr = classification_report(actual, pred)\n",
    "cm = confusion_matrix(actual,pred)\n",
    "print(cr)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.29      0.29         7\n",
      "           1       0.85      0.94      0.89        67\n",
      "           2       0.62      0.71      0.67         7\n",
      "           3       0.00      0.00      0.00         5\n",
      "           4       0.78      0.64      0.70        11\n",
      "           5       0.00      0.00      0.00         2\n",
      "           6       0.50      1.00      0.67         1\n",
      "\n",
      "    accuracy                           0.78       100\n",
      "   macro avg       0.43      0.51      0.46       100\n",
      "weighted avg       0.72      0.78      0.75       100\n",
      "\n",
      "[[ 2  4  0  0  0  0  1]\n",
      " [ 3 63  0  0  1  0  0]\n",
      " [ 1  0  5  0  1  0  0]\n",
      " [ 1  2  2  0  0  0  0]\n",
      " [ 0  4  0  0  7  0  0]\n",
      " [ 0  1  1  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  1]]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "predict_this=[]\n",
    "actual=[]\n",
    "x,y = next(valid_generator)\n",
    "for i in range(len(x)):\n",
    "    #plt.imshow(x[i])\n",
    "    #plt.show()\n",
    "#     print('label:',y[i])\n",
    "    actual.append(y[i])\n",
    "    predict_this.append(x[i])\n",
    "    #print('----------------------------------------------------------------------------------------')\n",
    "np.set_printoptions(suppress=True)    \n",
    "pred = model.predict(np.array(predict_this))\n",
    "\n",
    "#pred = tf.cast(pred, tf.float32)\n",
    "# print(pred)\n",
    "# print(type(pred))\n",
    "pred = np.argmax(pred, axis=1)\n",
    "actual = np.argmax(actual, axis=1)\n",
    "# print(pred)\n",
    "# print(actual)\n",
    "# if actual.all()==pred.all():\n",
    "#     print('WIN!!!!!!!!!!!!!!!')\n",
    "cr = classification_report(actual, pred)\n",
    "cm = confusion_matrix(actual,pred)\n",
    "print(cr)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 9s 2s/step\n",
      "loss, accuracy [0.7176942229270935, 0.7839999794960022]\n"
     ]
    }
   ],
   "source": [
    "print('loss, accuracy',model.evaluate(valid_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
